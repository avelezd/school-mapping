{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from glob import glob\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join('..', 'data')\n",
    "DATASET_DIR = os.path.join(DATA_DIR, 'datasets', '1')\n",
    "\n",
    "WIDTH = 300\n",
    "HEIGHT = 300\n",
    "CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39905, 9977)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DIR = os.path.join(DATASET_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATASET_DIR, 'test')\n",
    "\n",
    "train_files = glob(os.path.join(TRAIN_DIR, '*.jpg'))\n",
    "val_files = glob(os.path.join(VAL_DIR, '*.jpg'))\n",
    "\n",
    "n_train_samples = len(train_files)\n",
    "n_val_samples = len(val_files)\n",
    "\n",
    "n_train_samples, n_val_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/munshkr/.local/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(WIDTH, HEIGHT, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINABLE_LAYERS = 30\n",
    "FC_SIZE = 1024\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(FC_SIZE, activation='relu')(x)\n",
    "x = Dropout(DROPOUT)(x)\n",
    "predictions = Dense(CLASSES, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "model_final.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.SGD(lr=LR, momentum=MOMENTUM),\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    zoom_range=0.3,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    rotation_range=30)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39905 images belonging to 1 classes.\n",
      "Found 9977 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    classes=[''],\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    classes=[''],    \n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label_row(row):\n",
    "    labels = list(row.values())[1:]\n",
    "    labels = [int(label) for label in labels]\n",
    "    return labels\n",
    "\n",
    "def read_labels_dict(dataset_dir):\n",
    "    with open(os.path.join(dataset_dir, 'labels.csv')) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        return {row['img']: parse_label_row(row) for row in reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = read_labels_dict(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_generator(gen, labels_dict):\n",
    "    for x in gen:\n",
    "        idx = (gen.batch_index - 1) * gen.batch_size\n",
    "        filenames = gen.filenames[idx : idx + gen.batch_size]\n",
    "        labels = np.array([labels_dict[fname] for fname in filenames])\n",
    "        yield x[0], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = build_data_generator(train_generator, labels_dict)\n",
    "val_datagen = build_data_generator(validation_generator, labels_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"checkpoint.h5\",\n",
    "    monitor = 'val_acc',\n",
    "    verbose = 1,\n",
    "    save_best_only = True,\n",
    "    save_weights_only = False,\n",
    "    mode = 'auto',\n",
    "    period = 1)\n",
    "\n",
    "early = EarlyStopping(\n",
    "    monitor = 'val_acc',\n",
    "    min_delta = 0,\n",
    "    patience = 10,\n",
    "    verbose = 1,\n",
    "    mode = 'auto')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor = 'val_loss',\n",
    "    factor = 0.2,\n",
    "    patience = 5,\n",
    "    min_lr = 0.001)\n",
    "\n",
    "history = model_final.fit_generator(\n",
    "    train_datagen,\n",
    "    steps_per_epoch = n_train_samples // BATCH_SIZE,\n",
    "    epochs = EPOCHS, \n",
    "    validation_data = val_datagen,\n",
    "    validation_steps = n_val_samples // BATCH_SIZE,\n",
    "    callbacks = [checkpoint, early, reduce_lr])\n",
    "\n",
    "model_final.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
