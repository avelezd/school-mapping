{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montevideo: Dataset building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we build a dataset consisting of 300x300 RGB chips of an RGB mosaic satellite image. This image is a mosaic built from a WorldView-2 scene of Montevideo, Uruguay, acquired on 2017. Chips outside of AOI and on ocean are discarded.\n",
    "\n",
    "The methodology consists of building a multilabel classifier of 3 classes:\n",
    "* Urban areas\n",
    "* Rural areas\n",
    "* Schools\n",
    "\n",
    "To designate urban and rural areas, we are using shapefiles from the [Open Data Catalog](http://datos.gub.uy/) \n",
    "* [Urban lots](https://catalogodatos.gub.uy/dataset/shapes-del-parcelario-rural-y-urbano/resource/541d8db5-1ceb-40dd-9898-706d85209d04)\n",
    "* [Rural lots](https://catalogodatos.gub.uy/dataset/shapes-del-parcelario-rural-y-urbano/resource/74975837-c4ac-498c-b76d-fb1ff4e1fbaa)\n",
    "\n",
    "The schools dataset consist of a shapefile of points of known schools. We are interpreting a chip as \"school\" if a point is contained in that chip.\n",
    "\n",
    "Here is a rough pseudocode of the building procedure:\n",
    "\n",
    "```\n",
    "Open raster\n",
    "Open vector files\n",
    "Reproject vector files to match raster's\n",
    "Filter chips outside of AOI\n",
    "For each chip in raster:\n",
    "    Extract chip to directory\n",
    "    Set label for chip with vector files\n",
    "Write labels.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import fiona\n",
    "import numpy as np\n",
    "import os\n",
    "import rtree\n",
    "import pyproj\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "from shapely.geometry import shape, box \n",
    "from shapely.ops import transform\n",
    "from tqdm import tqdm_notebook\n",
    "from rasterio.windows import Window\n",
    "from skimage.io import imsave\n",
    "from skimage.exposure import is_low_contrast\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join('..', 'data')\n",
    "\n",
    "RASTER = os.path.join(DATA_DIR, 'montevideo', 'mosaic.tif')\n",
    "AOI_VECTOR = os.path.join(DATA_DIR, 'montevideo', 'aoi.shp')\n",
    "URBAN_VECTOR = os.path.join(DATA_DIR, 'montevideo', 'urban.shp')\n",
    "RURAL_VECTOR = os.path.join(DATA_DIR, 'montevideo', 'rural.shp')\n",
    "SCHOOL_VECTOR = os.path.join(DATA_DIR, 'montevideo', 'school.geojson')\n",
    "\n",
    "DATASET_DIR = os.path.join(DATA_DIR, 'ds2')\n",
    "WIDTH = 300\n",
    "HEIGHT = 300\n",
    "\n",
    "CLASSES = ('urban', 'rural', 'school')\n",
    "VECTORS_BY_CLASS = dict(urban=URBAN_VECTOR, rural=RURAL_VECTOR, school=SCHOOL_VECTOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract chips and labels from vector files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define some useful functions for building R-Tree indexes and reprojecting shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(shapes):\n",
    "    \"\"\"Create an R-Tree index from a set of shapes\"\"\"\n",
    "    index = rtree.index.Index()\n",
    "    for shape_id, shape in enumerate(shapes):\n",
    "        index.insert(shape_id, shape.bounds)\n",
    "    return index\n",
    "\n",
    "def reproject_shape(shape, src_crs, dst_crs):\n",
    "    \"\"\"Reprojects a shape from some projection to another\"\"\"\n",
    "    src_crs = dict(init=src_crs) if isinstance(src_crs, str) else src_crs\n",
    "    dst_crs = dict(init=dst_crs) if isinstance(dst_crs, str) else dst_crs\n",
    "    project = partial(\n",
    "        pyproj.transform,\n",
    "        pyproj.Proj(init=src_crs['init']),\n",
    "        pyproj.Proj(init=dst_crs['init']))\n",
    "    return transform(project, shape)\n",
    "\n",
    "def get_raster_crs(raster_path):\n",
    "    \"\"\"Return CRS of +raster_path+\"\"\"\n",
    "    with rasterio.open(raster_path) as dataset:\n",
    "        return dataset.crs\n",
    "    \n",
    "def get_shapes(vector_path, target_crs=None):\n",
    "    with fiona.open(vector_path) as dataset:\n",
    "        shapes = (shape(f['geometry']) for f in dataset if f['geometry'])\n",
    "        if dataset.crs != target_crs:\n",
    "            shapes = (reproject_shape(s, dataset.crs, target_crs) for s in shapes)\n",
    "        valid_shapes = [s for s in shapes if s.is_valid]\n",
    "        return valid_shapes\n",
    "\n",
    "def prepare_shapes_by_class(vectors_by_class, target_crs):\n",
    "    \"\"\"Load all shapes from each class vector file\"\"\"\n",
    "    return {class_name: get_shapes(vector_file, target_crs)\n",
    "            for class_name, vector_file in vectors_by_class.items()}\n",
    "\n",
    "def prepare_index_by_class(shapes_by_class):\n",
    "    \"\"\"Build R-Tree index for all classes\"\"\"\n",
    "    return {class_name: create_index(shapes)\n",
    "            for class_name, shapes in shapes_by_class.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shapes...\n",
      "Building indexes...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Load shapes for classes and build indexes for fast intersection\n",
    "raster_crs = get_raster_crs(RASTER)\n",
    "        \n",
    "print(\"Loading shapes...\")\n",
    "shapes_by_class = prepare_shapes_by_class(VECTORS_BY_CLASS,\n",
    "                                          target_crs=raster_crs['init'])\n",
    "print(\"Building indexes...\")\n",
    "index_by_class = prepare_index_by_class(shapes_by_class)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_intersecting_shape(wbox, shapes, index):\n",
    "    \"\"\"Return true iif any shapes intersects with window, or is contained in window\"\"\"\n",
    "    matching_shapes = [shapes[i] for i in index.intersection(wbox.bounds)]\n",
    "    if matching_shapes:\n",
    "        return any(shape.intersection(wbox) for shape in matching_shapes)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_window_labels(wbox, classes, *, shapes_by_class, index_by_class):\n",
    "    labels = {}\n",
    "    any_label = False\n",
    "    for class_name in classes:\n",
    "        shapes = shapes_by_class[class_name]\n",
    "        index = index_by_class[class_name]\n",
    "        labels[class_name] = any_intersecting_shape(wbox, shapes, index)\n",
    "    return labels\n",
    "        \n",
    "def sliding_windows(size, step_size, width, height):\n",
    "    \"\"\"Slide a window of +size+ by moving it +step_size+ pixels\"\"\"\n",
    "    w, h = size\n",
    "    sw, sh = step_size\n",
    "    for pos_i, i in enumerate(range(0, height - h + 1, sh)):\n",
    "        for pos_j, j in enumerate(range(0, width - w + 1, sw)):\n",
    "            yield Window(j, i, w, h), (pos_i, pos_j)\n",
    "\n",
    "def write_image(img, path):\n",
    "    rgb = np.dstack(img[:3, :, :])\n",
    "    if is_low_contrast(rgb):\n",
    "        return False\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    imsave(path, rgb)\n",
    "    return True\n",
    "\n",
    "def convert_bools(labels):\n",
    "    return {k: (1 if v else 0) for k, v in labels.items()}\n",
    "\n",
    "def filter_by_aoi(window_and_boxes, aoi_vector):\n",
    "    with fiona.open(aoi_vector) as src:\n",
    "        shapes = [shape(f['geometry']) for f in src]\n",
    "        assert len(shapes) == 1\n",
    "        aoi_shape = shapes[0]\n",
    "    return [w for w, b in window_and_boxes if aoi_shape.intersects(b)]\n",
    "\n",
    "def build_dataset(raster, aoi_vector=None, *, classes, shapes_by_class, index_by_class, width, height, output_dir):\n",
    "    with rasterio.open(raster) as ds:\n",
    "        print('Raster size: {}'.format((ds.width, ds.height)))\n",
    "        raster_crs = ds.crs\n",
    "\n",
    "        size = (width, height)\n",
    "        print(\"Building window list...\")\n",
    "        windows = list(sliding_windows(size, size, ds.width, ds.height))\n",
    "        print(\"Windows: \", len(windows))\n",
    "\n",
    "        print(\"Build window boxes...\")\n",
    "        windows_and_boxes = [(win, box(*ds.window_bounds(win[0]))) for win in windows]\n",
    "\n",
    "        print(\"Filtering windows by AOI...\")\n",
    "        windows = filter_by_aoi(windows_and_boxes, aoi_vector)\n",
    "        \n",
    "        print(\"Windows after filtering by AOI: \", len(windows))\n",
    "    \n",
    "        labels_path = os.path.join(output_dir, 'labels.csv')\n",
    "        os.makedirs(os.path.dirname(labels_path), exist_ok=True)\n",
    "        \n",
    "        with open(labels_path, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['img'] + list(classes)\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "        \n",
    "            for window, (i, j) in tqdm_notebook(windows):\n",
    "                #print(window, (i, j))\n",
    "                img = ds.read(window=window)\n",
    "\n",
    "                img_filename = '{i}_{j}.jpg'.format(i=i, j=j)\n",
    "                img_path = os.path.join(output_dir, 'all', img_filename)\n",
    "                was_image_written = write_image(img, img_path)\n",
    "\n",
    "                if was_image_written:\n",
    "                    # Get window labels\n",
    "                    wbox = box(*ds.window_bounds(window))\n",
    "                    labels = get_window_labels(wbox, classes, shapes_by_class=shapes_by_class, index_by_class=index_by_class)\n",
    "                    labels = convert_bools(labels)\n",
    "\n",
    "                    # Write labels to file\n",
    "                    labels['img'] = img_filename\n",
    "                    writer.writerow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster size: (109149, 76345)\n",
      "Building window list...\n",
      "Windows:  92202\n",
      "Build window boxes...\n",
      "Filtering windows by AOI...\n",
      "Windows after filtering by AOI:  45955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0330308542b46eb95d906d645029bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45955), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "build_dataset(RASTER,\n",
    "              width=WIDTH,\n",
    "              height=HEIGHT,\n",
    "              aoi_vector=AOI_VECTOR,\n",
    "              classes=CLASSES,\n",
    "              shapes_by_class=shapes_by_class,\n",
    "              index_by_class=index_by_class,\n",
    "              output_dir=DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get 9 random images of different classes, and plot them\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for i in range(1, 9):\n",
    "#     plt.subplot(2, 4, i)\n",
    "#     plt.axis('off')\n",
    "#     rand_y = random.randint(0, img.shape[0] - h)\n",
    "#     rand_x = random.randint(0, img.shape[1] - w)\n",
    "#     plt.imshow(img[rand_y:rand_y+h, rand_x:rand_x+w, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label_row(row):\n",
    "    return [int(row[k]) for k in CLASSES]\n",
    "\n",
    "def get_instances_and_labels_from_dataset(dataset_dir):\n",
    "    labels_path = os.path.join(dataset_dir, 'labels.csv')\n",
    "    with open(labels_path, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        rows = list(reader)\n",
    "    X = np.array([row['img'] for row in rows])\n",
    "    y = np.array([parse_label_row(row) for row in rows])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_instances_and_labels_from_dataset(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0_92.jpg', '0_93.jpg', '0_94.jpg', ..., '245_154.jpg',\n",
       "        '245_155.jpg', '246_155.jpg'], dtype='<U11'), array([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class balancing\n",
    "\n",
    "First we analyze how many instances are from each class combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('urban', 'rural', 'school')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_stats(y):\n",
    "    total = y.shape[0]\n",
    "\n",
    "    c_none = np.sum(np.all(y[:] == 0, axis=1))\n",
    "\n",
    "    c_urban = np.sum(y[:, 0])\n",
    "    c_rural = np.sum(y[:, 1])\n",
    "    c_school = np.sum(y[:, 2])\n",
    "\n",
    "    print(\"Total\", total)\n",
    "    print(\"None\", c_none, c_none / total)\n",
    "    print(\"Urban\", c_urban, c_urban / total)\n",
    "    print(\"Rural\", c_rural, c_rural / total)\n",
    "    print(\"School\", c_school, c_school / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 36213\n",
      "None 19059 0.5263027089719161\n",
      "Urban 8283 0.22873001408334023\n",
      "Rural 10132 0.27978902604037226\n",
      "School 256 0.007069284511087179\n"
     ]
    }
   ],
   "source": [
    "print_class_stats(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ints = [y.argmax() for y in y_train]\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_ints), y_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.44148197,   1.37076993, 185.70769231])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to subsample to create a smaller but more balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(X, y):\n",
    "    X_res, y_res = X[y[:, 2] == 1], y[y[:, 2] == 1]\n",
    "    class_len = len(y_res) * 8\n",
    "    indexes = [np.all(y == 0, axis=1), y[:, 0] == 1, y[:, 1] == 1]\n",
    "    for idx in indexes:\n",
    "        X_res = np.concatenate([X_res, X[idx][:class_len]])\n",
    "        y_res = np.concatenate([y_res, y[idx][:class_len]])\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, y2 = balance_dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6400,), (36213,))"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 6400\n",
      "None 2048 0.32\n",
      "Urban 2528 0.395\n",
      "Rural 2413 0.37703125\n",
      "School 308 0.048125\n"
     ]
    }
   ],
   "source": [
    "print_class_stats(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X2\n",
    "y_train = y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ints = [y.argmax() for y in y_train]\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_ints), y_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46620047,  1.21281031, 32.82051282])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6400,), (9054,))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dir = os.path.abspath(os.path.join(DATASET_DIR, 'all'))\n",
    "train_dir = os.path.abspath(os.path.join(DATASET_DIR, 'train'))\n",
    "test_dir = os.path.abspath(os.path.join(DATASET_DIR, 'test'))\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "for fname in X_train:\n",
    "    shutil.copyfile(os.path.join(all_dir, fname), os.path.join(train_dir, fname))\n",
    "\n",
    "for fname in X_test:\n",
    "    shutil.copyfile(os.path.join(all_dir, fname), os.path.join(test_dir, fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
