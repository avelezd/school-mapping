{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8aT6X_44YaQ"
   },
   "source": [
    "# Montevideo: Evaluation\n",
    "\n",
    "Now we evaluate model over validation set and only \"schools\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3N19ny0mGZ9C",
    "outputId": "d0264ba6-03ba-4acb-d821-235423a7874c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device name: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#@title Check GPU presence { display-mode: \"form\" }\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"GPU device name: {}\".format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "j5Qa-XrC4kUX",
    "outputId": "de2c144f-ab63-423c-faa1-8f6af45f97a9"
   },
   "outputs": [],
   "source": [
    "#@title Download datasets { display-mode: 'form' }\n",
    "#@test {'output': 'ignore'}\n",
    "\n",
    "#!mkdir -p 1/\n",
    "#!gcloud config set project golden-system-178513\n",
    "#!gsutil -m cp gs://dym-temp/school-mapping/datasets/1.tar.gz 1/\n",
    "#!cd 1/ && tar xzf 1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BTxDLYM84YaS",
    "outputId": "dee8cbbc-da1a-4148-bc7b-6cafaeba0d8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import gc\n",
    "\n",
    "from glob import glob\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras import backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VnJHH5f84YaZ"
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = '../data/ds2/'\n",
    "\n",
    "WIDTH = 300\n",
    "HEIGHT = 300\n",
    "CLASSES = ('urban', 'rural', 'school')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bYWxOJ3o4Yab",
    "outputId": "10ff3ca1-de7f-4f4d-8a0b-328297655f48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6055, 9054)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DIR = os.path.join(DATASET_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATASET_DIR, 'test')\n",
    "\n",
    "train_files = glob(os.path.join(TRAIN_DIR, '*.jpg'))\n",
    "val_files = glob(os.path.join(VAL_DIR, '*.jpg'))\n",
    "\n",
    "n_train_samples = len(train_files)\n",
    "n_val_samples = len(val_files)\n",
    "\n",
    "n_train_samples, n_val_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3FAB1SBh4Yav"
   },
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Bm71qyG4Yaw"
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wEawyjHt4Yay"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2es2bCxUk1vK"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Now we evaluate model over validation set and only \"schools\" class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "unoS5b-Qk3VR",
    "outputId": "05ded6c0-c47e-44ed-e5b0-0e1bd712c628"
   },
   "outputs": [],
   "source": [
    "#!gsutil cp gs://dym-temp/school-mapping/models/*.h5 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "A4S9_5ink-kN",
    "outputId": "7284d599-59e0-4dcf-f79c-b85bdc8ca122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "WEIGHTS_PATH = '../data/models/checkpoint.h5'\n",
    "\n",
    "FC_SIZE = 1024\n",
    "DROPOUT = 0.5\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = ResNet50(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(WIDTH, HEIGHT, 3))\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(FC_SIZE, activation='relu')(x)\n",
    "x = Dropout(DROPOUT)(x)\n",
    "predictions = Dense(len(CLASSES), activation='sigmoid')(x)\n",
    "model_final = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "print(\"Loading weights...\")\n",
    "model_final.load_weights(WEIGHTS_PATH)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = model_final.input_shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19569321, 0.12140249, 0.0098942 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = os.path.join(DATASET_DIR, 'test', '0_93.jpg')\n",
    "img = image.load_img(img_path, target_size=target_size)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model_final.predict(x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sz52VvaTn4Bh"
   },
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "from random import shuffle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "def predict_images(img_path, batch_size=40):\n",
    "    images = glob(os.path.join(img_path, '*.jpg'))\n",
    "    #shuffle(images)\n",
    "    all_preds = None\n",
    "    groups = list(enumerate(grouper(images, batch_size)))\n",
    "    for g, img_group in tqdm(groups):\n",
    "        imgs = [image.load_img(path, target_size=target_size) for path in img_group if path]\n",
    "        arrays = np.array([image.img_to_array(img) for img in imgs])\n",
    "        pre_arrays = preprocess_input(arrays)\n",
    "        preds = model_final.predict(pre_arrays)\n",
    "        preds = np.round(preds)\n",
    "        if all_preds is None:\n",
    "            all_preds = preds\n",
    "        else:    \n",
    "            all_preds = np.concatenate([all_preds, preds])            \n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd8778b1021497aa4c6a63e382411ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=152), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6055, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_images(os.path.join(DATASET_DIR, 'train'))\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_stats(y):\n",
    "    total = y.shape[0]\n",
    "\n",
    "    c_none = np.sum(np.all(y[:] == 0, axis=1))\n",
    "\n",
    "    c_urban = np.sum(y[:, 0])\n",
    "    c_rural = np.sum(y[:, 1])\n",
    "    c_school = np.sum(y[:, 2])\n",
    "\n",
    "    print(\"Total\", total)\n",
    "    print(\"None\", c_none, c_none / total)\n",
    "    print(\"Urban\", c_urban, c_urban / total)\n",
    "    print(\"Rural\", c_rural, c_rural / total)\n",
    "    print(\"School\", c_school, c_school / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 6055\n",
      "None 5771 0.9530966143682906\n",
      "Urban 0.0 0.0\n",
      "Rural 284.0 0.04690338563170933\n",
      "School 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print_class_stats(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Get labels from test dataset\n",
    "* Evaluate: Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g0jdyrpllxyw"
   },
   "outputs": [],
   "source": [
    "def parse_label_row(row):\n",
    "    labels = list(row.values())[1:]\n",
    "    labels = [int(label) for label in labels]\n",
    "    return labels\n",
    "\n",
    "def get_labels_from_data_subset(dataset_dir, subset_name):\n",
    "    labels_path = os.path.join(dataset_dir, 'labels.csv')\n",
    "    with open(labels_path, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        rows_by_img = { row['img']: row for row in reader }\n",
    "    images = glob(os.path.join(dataset_dir, subset_name, '*.jpg'))\n",
    "    basenames = [os.path.basename(img) for img in images]\n",
    "    instances_subset = [rows_by_img[img] for img in basenames]\n",
    "    y = np.array([parse_label_row(instance) for instance in instances_subset])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "4CjIfUdWnQ1M",
    "outputId": "77870ecc-c4d3-4a9e-be52-add1b96948f4"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '99_249.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-82fba8980717>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_labels_from_data_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-1d5a1966a404>\u001b[0m in \u001b[0;36mget_labels_from_data_subset\u001b[0;34m(dataset_dir, subset_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbasenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minstances_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrows_by_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbasenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparse_label_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstances_subset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-1d5a1966a404>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbasenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minstances_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrows_by_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbasenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparse_label_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstances_subset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-1d5a1966a404>\u001b[0m in \u001b[0;36mparse_label_row\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_label_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-1d5a1966a404>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_label_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '99_249.jpg'"
     ]
    }
   ],
   "source": [
    "y_true = get_labels_from_data_subset(DATASET_DIR, 'test')\n",
    "y_true.shape, y_true"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "School Mapping - Montevideo: Model.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
